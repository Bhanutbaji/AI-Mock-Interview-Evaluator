{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fer2013.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./dataset/fer2013/\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "87965c894d3b7f3b3dfc66d8c2a60efcc08a370d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emotion</td>\n",
       "      <td>pixels</td>\n",
       "      <td>Usage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>85 84 90 121 101 102 133 153 153 169 177 189 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     usage\n",
       "0  emotion                                             pixels     Usage\n",
       "1        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "2        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "3        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "4        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "5        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n",
       "6        2  55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...  Training\n",
       "7        4  20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...  Training\n",
       "8        3  77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...  Training\n",
       "9        3  85 84 90 121 101 102 133 153 153 169 177 189 1...  Training"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data\n",
    "filname = './dataset/fer2013/fer2013.csv'\n",
    "label_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "names=['emotion','pixels','usage']\n",
    "df=pd.read_csv('./dataset/fer2013/fer2013.csv',names=names, na_filter=False)\n",
    "im=df['pixels']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "bfde4d91ff367dfa6764202c1b309ea291fb833a"
   },
   "outputs": [],
   "source": [
    "def getData(filname):\n",
    "    # images are 48x48\n",
    "    # N = 35887\n",
    "    Y = []\n",
    "    X = []\n",
    "    first = True\n",
    "    for line in open(filname):\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            row = line.split(',')\n",
    "            Y.append(int(row[0]))\n",
    "            X.append([int(p) for p in row[1].split()])\n",
    "\n",
    "    X, Y = np.array(X) / 255.0, np.array(Y)\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "435d0e06553e3de3fd982e4a4a86c28018ac3913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "X, Y = getData(filname)\n",
    "num_class = len(set(Y))\n",
    "print(num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f3c6bfb7aaf3c25ba7cdd5621e4d62b9eaa5502e"
   },
   "outputs": [],
   "source": [
    "# keras with tensorflow backend\n",
    "N, D = X.shape\n",
    "X = X.reshape(N, 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "be4faef86c3c5635697f10939547edd5c8760308"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
    "y_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\n",
    "y_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "3afd36886a65ff49fe48ac73271f7477b574375a"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation , Dropout ,Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import *\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import backend as K  # Correct import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "c8eaecce539d06c983ed73142ac1484dbfa5e970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 64)        1664      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 64)        102464    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48, 48, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 128)       204928    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 128)       409728    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 12, 12, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1179776   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 128)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 7)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,787,015\n",
      "Trainable params: 2,785,863\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def my_model():\n",
    "    model = Sequential()\n",
    "    input_shape = (48,48,1)\n",
    "    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(7))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
    "    # UNCOMMENT THIS TO VIEW THE ARCHITECTURE\n",
    "    #model.summary()\n",
    "    \n",
    "    return model\n",
    "model=my_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "5004be413385dbdf6c3967d34c59e541095ea667"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "505/505 [==============================] - 32s 53ms/step - loss: 1.6674 - accuracy: 0.3582 - val_loss: 1.9108 - val_accuracy: 0.2700\n",
      "Epoch 2/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 1.2990 - accuracy: 0.5033 - val_loss: 1.2589 - val_accuracy: 0.5143\n",
      "Epoch 3/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 1.1249 - accuracy: 0.5768 - val_loss: 1.2136 - val_accuracy: 0.5330\n",
      "Epoch 4/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.9959 - accuracy: 0.6268 - val_loss: 1.1801 - val_accuracy: 0.5614\n",
      "Epoch 5/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.8699 - accuracy: 0.6800 - val_loss: 1.1053 - val_accuracy: 0.5918\n",
      "Epoch 6/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.7336 - accuracy: 0.7343 - val_loss: 1.2195 - val_accuracy: 0.5748\n",
      "Epoch 7/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.5669 - accuracy: 0.7958 - val_loss: 1.2144 - val_accuracy: 0.5979\n",
      "Epoch 8/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.4038 - accuracy: 0.8583 - val_loss: 1.5378 - val_accuracy: 0.5525\n",
      "Epoch 9/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.2716 - accuracy: 0.9066 - val_loss: 1.6325 - val_accuracy: 0.5887\n",
      "Epoch 10/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.1974 - accuracy: 0.9339 - val_loss: 2.0488 - val_accuracy: 0.5288\n",
      "Epoch 11/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.1585 - accuracy: 0.9488 - val_loss: 1.8186 - val_accuracy: 0.6121\n",
      "Epoch 12/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.1281 - accuracy: 0.9580 - val_loss: 2.1736 - val_accuracy: 0.4163\n",
      "Epoch 13/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.1200 - accuracy: 0.9609 - val_loss: 1.9418 - val_accuracy: 0.6043\n",
      "Epoch 14/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.1260 - accuracy: 0.9574 - val_loss: 1.9563 - val_accuracy: 0.5890\n",
      "Epoch 15/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.0962 - accuracy: 0.9686 - val_loss: 1.9861 - val_accuracy: 0.6069\n",
      "Epoch 16/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.0893 - accuracy: 0.9706 - val_loss: 2.1019 - val_accuracy: 0.6055\n",
      "Epoch 17/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.0791 - accuracy: 0.9745 - val_loss: 2.1259 - val_accuracy: 0.6082\n",
      "Epoch 18/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.0774 - accuracy: 0.9741 - val_loss: 2.3480 - val_accuracy: 0.5876\n",
      "Epoch 19/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.0840 - accuracy: 0.9713 - val_loss: 2.0785 - val_accuracy: 0.6172\n",
      "Epoch 20/20\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.0688 - accuracy: 0.9777 - val_loss: 2.3120 - val_accuracy: 0.6016\n"
     ]
    }
   ],
   "source": [
    "path_model='model_filter.h5' # save model at this location after each epoch\n",
    "# K.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\n",
    "K.clear_session()  # Correct method in TensorFlow 2.x\n",
    "\n",
    "model=my_model() # create the model\n",
    "K.set_value(model.optimizer.lr,1e-3) # set the learning rate\n",
    "# fit the model\n",
    "h=model.fit(x=X_train,     \n",
    "            y=y_train, \n",
    "            batch_size=64, \n",
    "            epochs=20, \n",
    "            verbose=1, \n",
    "            validation_data=(X_test,y_test),\n",
    "            shuffle=True,\n",
    "            callbacks=[\n",
    "                ModelCheckpoint(filepath=path_model),\n",
    "            ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "0c7e2abb2a89f4df0d28de0a49db1f60c84fbcf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "y_pos = np.arange(len(objects))\n",
    "print(y_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "077d44e8bbb7549a09682eb09c417903bf2fd935"
   },
   "outputs": [],
   "source": [
    "def emotion_analysis(emotions):\n",
    "    objects = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "    y_pos = np.arange(len(objects))\n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.9)\n",
    "    plt.tick_params(axis='x', which='both', pad=10,width=4,length=10)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "241291244491cc1e84a45ecb0da66c1c09a4cd7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3589, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "#print(y_pred)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e97d2cb00640d2bfc4d4de9456249e893f72cc2"
   },
   "outputs": [],
   "source": [
    "#import seaborn as sn\n",
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#%matplotlib inline\n",
    "#cm = confusion_matrix(np.where(y_test == 1)[1], y_pred)\n",
    "#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#df_cm = pd.DataFrame(cm, index = [i for i in \"0123456\"],\n",
    "                  #columns = [i for i in \"0123456\"])\n",
    "#plt.figure(figsize = (20,15))\n",
    "#sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Real Time Expression Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "70fc48e66d18c54ba629e625ad8def5ad2d93fa6"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io\n\u001b[0;32m      2\u001b[0m img \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mload_img(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./faces/face_180_0.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, grayscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[0;32m      3\u001b[0m show_img\u001b[38;5;241m=\u001b[39mimage\u001b[38;5;241m.\u001b[39mload_img(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./faces/face_180_0.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, grayscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "from skimage import io\n",
    "img = image.load_img('./faces/face_180_0.jpg', grayscale=True, target_size=(48, 48))\n",
    "show_img=image.load_img('./faces/face_180_0.jpg', grayscale=False, target_size=(200, 200))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "\n",
    "x /= 255\n",
    "\n",
    "custom = model.predict(x)\n",
    "#print(custom[0])\n",
    "emotion_analysis(custom[0])\n",
    "\n",
    "x = np.array(x, 'float32')\n",
    "x = x.reshape([48, 48]);\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(show_img)\n",
    "plt.show()\n",
    "\n",
    "m=0.000000000000000000001\n",
    "a=custom[0]\n",
    "for i in range(0,len(a)):\n",
    "    if a[i]>m:\n",
    "        m=a[i]\n",
    "        ind=i\n",
    "        \n",
    "print('Expression Prediction:',objects[ind])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82db72b60f80eb18474bf880369791cf346c9749"
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "img = image.load_img('../input/testimages/wallpaper2you_443897.jpg', grayscale=True, target_size=(48, 48))\n",
    "show_img=image.load_img('../input/testimages/wallpaper2you_443897.jpg', grayscale=False, target_size=(200, 200))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "\n",
    "x /= 255\n",
    "\n",
    "custom = model.predict(x)\n",
    "#print(custom[0])\n",
    "emotion_analysis(custom[0])\n",
    "\n",
    "x = np.array(x, 'float32')\n",
    "x = x.reshape([48, 48]);\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(show_img)\n",
    "plt.show()\n",
    "\n",
    "m=0.000000000000000000001\n",
    "a=custom[0]\n",
    "for i in range(0,len(a)):\n",
    "    if a[i]>m:\n",
    "        m=a[i]\n",
    "        ind=i\n",
    "        \n",
    "print('Expression Prediction:',objects[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Live Demo of Production Level Project**\n",
    "\n",
    "[Facial Expression Detection Web App](https://faceai.herokuapp.com/)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 31050,
     "sourceId": 39603,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 35382,
     "sourceId": 47835,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 35907,
     "sourceId": 52857,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 12783,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
